{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "from datetime import datetime, timezone, timedelta\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "from bson.son import SON\n",
    "import json\n",
    "from bson import ObjectId\n",
    "from bson.json_util import dumps\n",
    "import time\n",
    "import pymongo\n",
    "import gridfs\n",
    "import logging\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 创建数据库和表\n",
    "如果不存在，则创建，否则切换到指定位置。\n",
    "https://blog.csdn.net/yisun123456/article/details/78591255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient(\"mongodb://192.168.5.106:27017/\")\n",
    "# db = client.autoops\n",
    "# db = client['admin']\n",
    "# db.add_user('root', '123456', roles=[{\n",
    "#     'role':'userAdminAnyDatabase',\n",
    "#     'db':'admin',\n",
    "# }])\n",
    "# db.authenticate(name=\"autoops\", password=\"autoops\")\n",
    "# db.createUser(\n",
    "#   {\n",
    "#     user: \"root\",\n",
    "#     pwd: \"123456\",\n",
    "#     roles: [ { role: \"userAdminAnyDatabase\", db: \"admin\" } ]\n",
    "#   }\n",
    "# )\n",
    "# db.authenticate(name=\"root\", password=\"123456\")\n",
    "# db.command(\"show user\")\n",
    "\n",
    "db = client[\"autoops_cycle\"]\n",
    "# db.add_user('autoops', 'autoops', roles=[{\n",
    "#     'role':'readWrite',\n",
    "#     'db':'autoops_cycle',\n",
    "# }])\n",
    "\n",
    "# db.getUsers()\n",
    "# r = db[\"system.users\"].find()\n",
    "# list(r)\n",
    "\n",
    "db.authenticate(name=\"autoops\", password=\"autoops\")\n",
    "\n",
    "# db.dropDatabase()\n",
    "# collection = db.train_result\n",
    "# dir(db)\n",
    "collection = db['datastream_datas']\n",
    "# collection.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"0718_1.csv\")\n",
    "data_entities = df.to_dict(orient='records')\n",
    "result = collection.insert_many(data_entities)\n",
    "\n",
    "del df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'collection' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-87c7d0107d03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# print(dir(gc))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# import os\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"datastreamId\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"_id\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'collection' is not defined"
     ]
    }
   ],
   "source": [
    "# { field: { $exists: <boolean> } }\n",
    "# collection.drop()\n",
    "# import gc\n",
    "# print(dir(gc))\n",
    "# import os\n",
    "r = collection.find({\"datastreamId\": 8}, {\"_id\": 0})\n",
    "data = list(r)\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(df.head())\n",
    "# print(dir(r))\n",
    "# print(dir(client))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(\"data.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(700, 10, 10)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gc.get_objects()\n",
    "gc.get_threshold()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(tmp_data.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "del tmp_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(tmp[0])\n",
    "del tmp\n",
    "del result\n",
    "# import sys\n",
    "# tmp_div = 1024*1024*8\n",
    "# print(sys.getsizeof(result)/tmp_div, \"MB\")\n",
    "# print(sys.getsizeof(tmp)/tmp_div, \"MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000000\n"
     ]
    }
   ],
   "source": [
    "tmp = {'Unnamed: 0': 0, 'back_flow': 1.5, 'batch_name': '165041A01-N14-P2', 'create_time': '2019-07-11', 'cycle': 24.33, 'cycle_count': 557290, 'extrude_torque': 8.9, 'id': 254626545, 'inject_pressure': 1.2, 'insert_time': '2019-07-15 14:49:18', 'machine_no': '3FB24', 'screw_pos': 29.5, 'screw_velocity': 1.5, 'start_time': '2019-07-11 05:39:29.000', 'start_time_source': '2019-07-11 05:39:29', 'time_stamp': 0, 'unixtime_stamp': 1562794769000}\n",
    "\n",
    "data = []\n",
    "index = 1000000\n",
    "while index > 0:\n",
    "    tmp[\"index\"] = index\n",
    "    data.append(tmp.copy())\n",
    "    index -= 1\n",
    "print(len(data))\n",
    "# json.loads()\n",
    "# del tmp_data\n",
    "# del df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 数据写入\n",
    "使用字典格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'db' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-6e044ce414b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcollection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatastream_datas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# collection.drop()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mquery_latest_and_earliest_time_of_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfact_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"datastreamId\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m85\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#     pipeline = [\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'db' is not defined"
     ]
    }
   ],
   "source": [
    "collection = db.datastream_datas\n",
    "# collection.drop()\n",
    "def query_latest_and_earliest_time_of_data(fact_id):\n",
    "    r = collection.find({\"datastreamId\": 85}).limit(100)\n",
    "#     pipeline = [\n",
    "#         {\"$match\": {\"factId\": {\"$eq\": fact_id}}},\n",
    "#         {\"$group\": {\"_id\": None, \"startTime\": {\"$min\": \"$startTime\"}, \"endTime\": {\"$max\": \"$endTime\"}}},\n",
    "#         {\"$project\": {\"_id\": 0}},\n",
    "#     ]\n",
    "#     r = collection.aggregate(pipeline)\n",
    "#     print(list(r))\n",
    "    r = list(r)\n",
    "\n",
    "    return r\n",
    "\n",
    "r = query_latest_and_earliest_time_of_data(1)\n",
    "pprint(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collection.drop()  # 测试用，先清空表内容\n",
    "\n",
    "# 准备数据\n",
    "time_format = \"%Y-%m-%d %H:%M:%S.%f\"\n",
    "time_zone = 8\n",
    "\n",
    "\n",
    "def strtime_2_utctimestamp(datetime_str):\n",
    "    datetime_obj = datetime.strptime(datetime_str, time_format)\n",
    "    datetime_utc = datetime_obj.replace(tzinfo=timezone(timedelta(hours=time_zone)))\n",
    "    return datetime_utc.timestamp()\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"./data/facts1.csv\")  # 读入原始数据\n",
    "\n",
    "# #  根据keyword 过滤数据\n",
    "# df = df.loc[df['keyword'].isin(keyword_list)]\n",
    "\n",
    "# 将时间列的时间表示为数值型的时间戳\n",
    "df['time'] = df['time'].apply(strtime_2_utctimestamp)\n",
    "df['end'] = df['end'].apply(strtime_2_utctimestamp)\n",
    "\n",
    "# print(df[time_end_col_name][0])\n",
    "fact_datas_list = []\n",
    "num = 0\n",
    "for index, row in df.iterrows():\n",
    "    fact_data_dict = {\n",
    "        \"factId\": 64,\n",
    "        \"startTime\": datetime.fromtimestamp(row[\"time\"], tz=timezone.utc),\n",
    "        \"endTime\": datetime.fromtimestamp(row[\"end\"], tz=timezone.utc),\n",
    "        \"entity\": row[\"person\"],\n",
    "        \"value\": row[\"activity\"],\n",
    "        \"keyword\": row[\"keyword\"],\n",
    "        \"additionalKeyword\": \"\",\n",
    "    }\n",
    "    fact_datas_list.append(fact_data_dict)\n",
    "#     if num == 2:\n",
    "#         break\n",
    "#     num += 1\n",
    "# pprint(fact_datas_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['_InsertManyResult__acknowledged', '_InsertManyResult__inserted_ids', '_WriteResult__acknowledged', '__class__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '_raise_if_unacknowledged', 'acknowledged', 'inserted_ids']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# collection.drop()\n",
    "def save_test_datas(data: list):\n",
    "    result = collection.insert_many(data)\n",
    "    print(dir(result))\n",
    "    return len(result.inserted_ids)\n",
    "\n",
    "save_test_datas(fact_datas_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__class__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getinitargs__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', 'dst', 'fromutc', 'max', 'min', 'tzname', 'utc', 'utcoffset']\n",
      "2017-04-11 15:49:13+00:00\n",
      "<class 'datetime.datetime'>\n",
      "1491925653.469\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# collection = db.datastream_datas\n",
    "# collection.drop()\n",
    "def query_all():\n",
    "#     condition = [{'datastreamId': 1}, {'_id': {'$where': 'this._id % 30 > 0'}}, {'_id': {'$where': 'this._id % 30 <= 15'}}]\n",
    "#     result = collection.find({'datastreamId': 44}, {'_id': 0,'haha': \"$_id\"}).limit(1)\n",
    "    \n",
    "    time = datetime.fromtimestamp(1491925753, tz=timezone.utc)\n",
    "    \n",
    "    print(dir(timezone))\n",
    "    print(time)\n",
    "    print(type(time))\n",
    "    print(datetime(2017, 4, 11, 15, 47, 33, 469000).replace(tzinfo=timezone.utc).timestamp())\n",
    "#     time = datetime(time)\n",
    "#     print(time)\n",
    "    result = collection.find({\"factId\": {\"$lte\":65}, \"startTime\": {\"$lte\": time}},{\"_id\":0}).limit(5)\n",
    "    return list(result)\n",
    "\n",
    "r = query_all()\n",
    "pprint(r)\n",
    "\n",
    "# print(\"hah{}\".format(1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 查询"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# collection.drop()  # 测试用，先清空表内容\n",
    "# save_test_datas(fact_datas_list)\n",
    "def query_all():\n",
    "    result = collection.find()\n",
    "    return list(result)\n",
    "\n",
    "r = query_all()\n",
    "pprint(r)\n",
    "\n",
    "def query_fact_datas():\n",
    "    result = collection.find({\"factId\": {\"$exists\": True}}, {\"factId\": 1, \"_id\": 0}).sort(\n",
    "        [(\"_id\", pymongo.DESCENDING)]).limit(4).skip(2)\n",
    "#     result = collection.find({\"$or\": [{'factId': 1}, {'keyword': {\"$eq\": \"Training\"}}]})\n",
    "    return list(result)\n",
    "\n",
    "# r = query_fact_datas()\n",
    "# pprint(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'_id': 1, 'results': [85, 88, 82]}]\n"
     ]
    }
   ],
   "source": [
    "collection.drop()  # 测试用，先清空表内容\n",
    "# 查询特殊行The following query matches only those documents where the results array contains at least one element that is both greater than or equal to 80 and is less than 85.\n",
    "def query_fact_datas():\n",
    "#     result = collection.find({\"$and\": [{ 'results': { '$elemMatch': { '$gte': 80, '$lt': 85 } }},{\"_id\": 2}]},)\n",
    "    result = collection.find({ 'results': { '$elemMatch': { '$gte': 76, '$lte': 82 } } })\n",
    "    return list(result)\n",
    "\n",
    "test_data = [\n",
    "    { '_id': 1, 'results': [ 85, 88, 82 ] },\n",
    "    { '_id': 2, 'results': [ 75, 88, 89 ] }]\n",
    "\n",
    "\n",
    "save_test_datas(test_data)\n",
    "\n",
    "r = query_fact_datas()\n",
    "pprint(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'_id': 1,\n",
      "  'name': 'haha',\n",
      "  'results': [{'product': 'abc', 'score': 10}, {'product': 'xyz', 'score': 5}]},\n",
      " {'_id': 2,\n",
      "  'name': 'haha',\n",
      "  'results': [{'product': 'abc', 'score': 8}, {'product': 'xyz', 'score': 7}]},\n",
      " {'_id': 3,\n",
      "  'name': 'heihei',\n",
      "  'results': [{'product': 'abc', 'score': 7}, {'product': 'xyz', 'score': 8}]}]\n"
     ]
    }
   ],
   "source": [
    "collection.drop()  # 测试用，先清空表内容\n",
    "# 查询特殊行\n",
    "def query_fact_datas():\n",
    "    result = collection.find({ 'results': { '$elemMatch': { \"product\": {\"$regex\" :\"xyz*\"}} }})\n",
    "    return list(result)\n",
    "\n",
    "test_data = [\n",
    "    { '_id': 1, \"name\": \"haha\", 'results': [ { 'product': \"abc\", 'score': 10 }, { 'product': \"xyz\", 'score': 5 } ] },\n",
    "    { '_id': 2, \"name\": \"haha\", 'results': [ { 'product': \"abc\", 'score': 8 }, { 'product': \"xyz\", 'score': 7 } ] },\n",
    "    { '_id': 3, \"name\": \"heihei\", 'results': [ { 'product': \"abc\", 'score': 7 }, { 'product': \"xyz\", 'score': 8 } ] }]\n",
    "\n",
    "\n",
    "save_test_datas(test_data)\n",
    "\n",
    "r = query_fact_datas()\n",
    "pprint(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 删除数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n"
     ]
    }
   ],
   "source": [
    "def delete_fact_datas():\n",
    "    result = collection.delete_many({\"factId\": 11})\n",
    "    # result = collection.delete_one({\"factId\": 1})\n",
    "#     collection.drop()\n",
    "    return result.deleted_count\n",
    "    \n",
    "r = delete_fact_datas()\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 更新数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'collection' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-124df87a5c96>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mupdate_fact_datas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mpprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-124df87a5c96>\u001b[0m in \u001b[0;36mupdate_fact_datas\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# modify = {\"$set\": {\"entity\": 2}}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#     result = collection.update_one({\"_id\": {\"$exist\": True}}, modify)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"_id\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"$eq\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodify\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'collection' is not defined"
     ]
    }
   ],
   "source": [
    "def update_fact_datas():\n",
    "    modify = {\"$set\": {\"heihei\": 2, \"haha\": 2}}\n",
    "    # modify = {\"$set\": {\"entity\": 2}}\n",
    "#     result = collection.update_one({\"_id\": {\"$exist\": True}}, modify)\n",
    "    result = collection.update_many({\"_id\": {\"$eq\": 1}}, modify)\n",
    "    return result\n",
    "\n",
    "update_fact_datas()\n",
    "r = query_all()\n",
    "pprint(r)\n",
    "\n",
    "print(\"-------------------------------\")\n",
    "\n",
    "def update_fact_datas():\n",
    "    modify = {\"$unset\": {\"heihei\": 2}}\n",
    "    # modify = {\"$set\": {\"entity\": 2}}\n",
    "#     result = collection.update_one({\"_id\": {\"$exist\": True}}, modify)\n",
    "    result = collection.update_many({\"_id\": {\"$eq\": 1}}, modify)\n",
    "    return result\n",
    "\n",
    "update_fact_datas()\n",
    "r = query_all()\n",
    "pprint(r)\n",
    "\n",
    "print(\"-------------------------------\")\n",
    "\n",
    "def update_fact_datas():\n",
    "    modify = {\n",
    "        \"id\": 3,\n",
    "        \"name\": '12'\n",
    "    }\n",
    "    result = collection.replace_one({\"_id\": {\"$gt\": 2}}, modify)\n",
    "    return result\n",
    "\n",
    "update_fact_datas()\n",
    "r = query_all()\n",
    "pprint(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 聚合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'_id': ObjectId('5d076c96c676ed4535a99926'),\n",
      "  'haha': ObjectId('5d076c96c676ed4535a99926')}]\n"
     ]
    }
   ],
   "source": [
    "def count_fact_datas():\n",
    "    pipeline = [\n",
    "#         {\"$unwind\": \"$results\"},\n",
    "#         {\"$match\": {\"factId\": {\"$gt\": 5}}},\n",
    "#         {\"$match\": {\"factId\": {\"$mod\": [2, {\"$eq\": 1}]}}},\n",
    "        { \"$project\" : {\"_id\": 1, \"haha\": \"$_id\"}},\n",
    "#         {\"$group\": {\"_id\": \"$factId\",  \"num\": {\"$sum\": 1}}},\n",
    "#         {'$sample': {'size': 30}},\n",
    "#         {\"$sort\": SON([(\"_id\", 1), (\"count\", 1)])},\n",
    "        {\"$limit\": 1},\n",
    "    ]\n",
    "    r = collection.aggregate(pipeline)\n",
    "    return list(r)\n",
    "\n",
    "r = count_fact_datas()\n",
    "pprint(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 大文件存储gridfsDb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'client' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-3815bc05fbc4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0mfile_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-3815bc05fbc4>\u001b[0m in \u001b[0;36mfile_save\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfile_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mgridfsDb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgridfs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0;31m# print(dir(gridfsDb.fs.files))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mgridfsDb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'client' is not defined"
     ]
    }
   ],
   "source": [
    "def find_files():\n",
    "    gridfsDb = client.gridfs\n",
    "    someFile = gridfsDb.fs.files.find_one({\"file_name\": \"green_alpha_1x1.png\"})\n",
    "    \n",
    "    print(type(gridfsDb.fs.files))\n",
    "    print(dir(gridfsDb.fs.files))\n",
    "    # gridfsDb = client.gridfs\n",
    "    fs = gridfs.GridFS(gridfsDb)\n",
    "    print(someFile[\"_id\"])\n",
    "    tmp_file = fs.get(someFile[\"_id\"])\n",
    "\n",
    "    # print(dir(tmp_file))\n",
    "    # print(tmp_file.read())\n",
    "    # print(type(tmp_file))\n",
    "    with open('myfile.png', 'wb') as f:\n",
    "        f.write(tmp_file.read())\n",
    "    # gridfsDb.fs.download_to_stream(someFile, file)\n",
    "    return someFile\n",
    "\n",
    "\n",
    "def file_save():\n",
    "    gridfsDb = client.gridfs\n",
    "    # print(dir(gridfsDb.fs.files))\n",
    "    gridfsDb.fs.files.remove()\n",
    "    fs = gridfs.GridFS(gridfsDb)\n",
    "    with open(\"./data/green_alpha_1x1.png\", \"rb\") as f:\n",
    "        a = fs.put(f.read(), file_name=\"green_alpha_1x1.png\")\n",
    "    # a = fs.put(f)\n",
    "    print(a)\n",
    "\n",
    "file_save()\n",
    "\n",
    "r = find_files()\n",
    "pprint(r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
